# -*- coding: utf-8 -*-
"""CCF394 Aula 6 classificadores Fashion_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cxgFje5hHim4Nuy6KaGfMbuglrY0vkKL

### Fashion MNIST

Este guia usa a base de dados Fashion MNIST que contém 70.000 imagens a preto e branco de 10 categorias diferentes. As imagens apresentam peças de roupa individuais com pouca resolução (28 por 28 píxeis)




Então, dada uma imagem de entrada, as saídas de rótulo são os tipos de roupas.
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"] 

No total, o conjunto de dados Fashion MNIST contém ** 70.000 ** imagens, o que sem dúvida é suficiente para começarmos. Das 70.000 imagens, usaremos ** 60.000 delas para treinar a rede neural com as outras 10.000 sendo usadas para testar a rede neural **. Lembre-se também de que cada imagem é uma imagem de 28px x 28px, o que significa que existem 784 bytes. E assim, o trabalho seria simplesmente pegar os 784 bytes como entrada e então produzir um dos 10 itens diferentes de roupa que a imagem representa.
"""

#!pip install -q tensorflow tensorflow-datasets matplotlib

from __future__ import absolute_import, division, print_function

#Importing Tensorflow and Tensorflow Datasets

import tensorflow as tf
import tensorflow_datasets as tfds

#Helper Libraries

import math
import numpy as np
import matplotlib.pyplot as plt

#Improve Progress Bar Display

import tqdm
import tqdm.auto
tqdm.tqdm = tqdm.auto.tqdm
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix

print('Tensorflow version: %s' % tf.__version__)

"""#usando o dataset do tensorFlow"""

dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)
train_dataset, test_dataset = dataset['train'], dataset['test']

class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

class_names

"""<b>Explorando....</b>

veja o tamanho dos conjuntos de treinamento e teste !
"""

num_train_examples = metadata.splits['train'].num_examples
num_test_examples = metadata.splits['test'].num_examples

print("Numero de exemplos de treinamento: {}".format(num_train_examples))
print("Numero de exemplos de teste: {}".format(num_test_examples))

"""<b>Pre-Processamento dos dados</b>
Os valores dos pixels variam de 0 a 255. Para o rpocessamento, é melhor normalizar os valores entre 0 e 1, para ter uma escala única.

"""

def normalize(images, labels):
    images = tf.cast(images, tf.float32)
    images /= 255
    return images, labels

# A função map aplica a função de normalização a cada elemento nos conjuntos de dados de treinamento e teste

train_dataset = train_dataset.map(normalize)
test_dataset = test_dataset.map(normalize)

"""Então, na função normalize, convertemos cada valor de pixel em um float. A partir daí, normalizamos o intervalo de valores de pixel para um número entre 0 e 1 em vez de 0 e 255. Essa técnica é muito utilizada em Machine Learning. E depois disso, retornamos o par de imagens e rótulos

Apresentando uma imagem
"""

# seleciona uma imagem, no formato 28x28

for image, label in test_dataset.take(1):
    break
image = image.numpy().reshape((28,28))



plt.figure()
plt.imshow(image, cmap=plt.cm.binary)
plt.colorbar()
plt.grid(False)
plt.show()

"""Agora, 25 imagens"""

plt.figure(figsize=(10,10))
i = 0

for (image,label) in test_dataset.take(25):
    image = image.numpy().reshape((28,28))
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(image, cmap=plt.cm.binary)
    plt.xlabel(class_names[label])
    i += 1
plt.show()

"""Construindo nosso modelo, ou seja, nossa de (CNN) para classificação
Os parâmetros levam en conta o tamanho da imagem (28x28x1) a função de ativação relu e softmax (usada nas camadas de saida).

"""

mnist_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

"""As 3 camadas da redeAs seen, the network has 3 input layers:

- <b>input</b> <code>tf.keras.layers.Flatten</code> - Essa camada transforma uma matriz 2-d (matriz) em uma matriz 1-D de 784 (28 x 28). Pense nessa camada como alinhando as imagens de um quadrado para uma linha longa. Esta camada não aprende nada; ele simplesmente remodela os dados.
- <b>"hidden"</b> <code>tf.keras.layers.Dense</code> -Uma camada densamente conectada de 126 neurônios. Cada neurônio (também conhecido como nó) recebe entrada de todos os 784 nós da camada anterior, ponderando essa entrada de acordo com os parâmetros ocultos que serão aprendidos durante o treinamento e emite um único valor para a próxima camada.
- <b>output</b> <code>tf.keras.layers.Dense</code> Esta é uma camada softmax de 10 nós com cada nó representando uma classe de roupa. Como na camada anterior, cada nó recebe a entrada dos 128 nós da camada anterior, pondera essa entrada de acordo com os parâmetros aprendidos e, em seguida, gera um valor na forma de [0, 1] que, obviamente, representa a probabilidade de da imagem pertencente a essa classe. A soma de todos os 10 nós é 1.

<b>Compilando o modelo</b>


Antes que o modelo esteja pronto para o treinamento, ele precisa de mais algumas configurações. Eles são adicionados durante a etapa de compilação do modelo:

- Loss function - Função de perda - Um algoritmo para medir a distância entre as saídas do modelo e a saída desejada. O objetivo do treinamento é a perda dessa medida.
- Optimizer - Um algoritmo para ajustar os parâmetros internos do modelo para minimizar a perda.
- Métricas - Usadas para monitorar as etapas de treinamento e teste. O exemplo a seguir usa precisão, a fração das imagens que são classificadas corretamente:
"""

mnist_model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#resumo da rede
mnist_model.summary()

"""##Apresentando o modelo"""

tf.keras.utils.plot_model(mnist_model, show_shapes=True)

"""Definindo o treinamento

1. Repita para sempre especificando <code> dataset.repeat() </code> (o parâmetro <code> epochs </code> descrito abaixo limita por quanto tempo realizamos o treinamento).
2. O <code> dataset.shuffle (60000) </code> randomiza a ordem para que nosso modelo não possa aprender nada com a ordem dos exemplos.
3. E <code> dataset.batch (32) </code> diz ao <code> model.fit </code> para usar lotes de 32 imagens e rótulos ao atualizar as variáveis ​​do modelo.

O treinamento é realizado chamando o método <code> model.fit </code>:

1. Alimente os dados de treinamento para o modelo usando <code> train_dataset </code>.
2. O modelo aprende a associar imagens e rótulos.
3. O parâmetro <code> epochs = 5 </code> limita o treinamento a 5 iterações completas do conjunto de dados de treinamento, portanto, um total de 5 * 60.000 = 300.000 exemplos.
(Não se preocupe com <code> steps_per_epoch </code>, o requisito para ter esse sinalizador será removido em breve.)
"""

BATCH_SIZE = 32
train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)

#ajustando a rede (treinando) e armazenando os dados de treinamento en history
history = mnist_model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))

pd.DataFrame(history.history).plot(title="Treinamento e resultados de validação",figsize=(7,5));

"""Como você pode ver, as métricas de perda e precisão são exibidas claramente. Após executar a 5ª época, podemos ver que temos uma perda de ~ 29% com nosso modelo sendo 89% preciso.

<b>Testando o modelo</b>

Depois de treinado , vamos aplicar o conjunto de teste para ver os resultados de classificação
"""

test_loss, test_accuracy = mnist_model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))

"""Observando nossos dados, a precisão do conjunto de dados de teste é semelhante ao conjunto de dados de treinamento (87% e 89%). Isso é totalmente esperado, pois o modelo foi treinado em train_dataset. Quando o modelo vê imagens que não viu antes (neste caso, test_dataset), poderíamos esperar que a precisão tivesse caído um pouco.

<b>como fazer uma predição de um dado ?</b>

com o modelo ajustado, vamos prever (classificar) alguns dados de entrada
"""

for test_images, test_labels in test_dataset.take(1):
  test_images = test_images.numpy()
  test_labels = test_labels.numpy()
  predictions = mnist_model.predict(test_images)

print(predictions.shape)
print(predictions[0].shape)

"""Aqui, o modelo previu as 32 respostas, cada uma com a distribuição de probabilidade contendo as 10 classes de que falamos anteriormente. Por que não dar uma olhada no primeiro?"""

predictions[5]

np.argmax(predictions[5])

"""o modelo então respondeu que a saida mais provável de ser a correta coi a saida 4, pois teve maior valor."""

test_labels[5]

def plot_image(i, predictions_array, true_labels, images):
  predictions_array, true_labels, img = predictions_array[i], true_labels[i], images[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img[...,0], cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_labels:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f} ({})".format(class_names[predicted_label], 100*np.max(predictions_array), class_names[true_labels]), color=color)

def plotting_probabilities(i, predictions_array, true_labels):
  predictions_array, true_labels = predictions_array[i], true_labels[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0,1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_labels].set_color('blue')

"""Vamos plotar várias imagens e ver suas previsões. Observe que as previsões corretas são azuis e as incorretas são vermelhas. O número fornece uma porcentagem (de 100) para o rótulo previsto. Observe também que o modelo pode estar muito errado apesar de apresentar um alto valor de confiança."""

#Mostra as imagens, a classe de saída e o valor de confianca

num_rows = 3
num_cols = 5

num_images = num_rows*num_cols

plt.figure(figsize=(2*2*num_cols, 2*num_rows))

for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plotting_probabilities(i, predictions, test_labels)

"""###Matriz de confusão"""

dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)
train_dataset, test_dataset = dataset['train'], dataset['test']

test_dataset.map(normalize)

BATCH_SIZE = 8192 # imagens de teste
train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)

for test_images, test_labels in test_dataset.take(1):
  test_images = test_images.numpy()
  test_labels = test_labels.numpy()
  predictions = mnist_model.predict(test_images)

print('Total de imagens de teste: %d'  % int(test_images.size/784))
print(saida.size/10)

#obtendo a previsão com os valores de teste para o modelo
y_probs = mnist_model.predict(test_images)

#Convert prediction probabilities into integers
y_preds = y_probs.argmax(axis=1)

#Confusion matrix
cm=confusion_matrix(y_preds,test_labels)
#Plot
disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_labels)
fig, ax = plt.subplots(figsize=(10,10))
disp.plot(ax=ax);

